{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1210d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def cal_acc(outputs,labels):\n",
    "    pred_labels=torch.max(outputs,1)[1]\n",
    "    equality = torch.eq(pred_labels,labels).float()\n",
    "    accuracy = torch.mean(equality)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def validation(model, validation_loader, criterion):\n",
    "    '''\n",
    "    The function take in the model, dataloader, lossfunction to calculate the loss and accuray, \n",
    "    it returns list of predicted labels and original labels as well  \n",
    "    \n",
    "    Param:\n",
    "    model: Model to make prediction\n",
    "    validation_loader: DataLoader that loads the data you want to make prediction on\n",
    "    criterion: Loss function to calculate loss\n",
    "    \n",
    "    Return:\n",
    "    val_loss: Loss value \n",
    "    val_acc: Accuracy value\n",
    "    output_list: List of predicted labels\n",
    "    labels_list: List of original labels\n",
    "    '''\n",
    "    validation_loss = 0\n",
    "    accuracy = 0\n",
    "    output_list=[]\n",
    "    labels_list=[]\n",
    "    for images, labels in validation_loader:\n",
    "        \n",
    "        labels_list.append(labels)\n",
    "        outputs = model(images)\n",
    "        output_list.append(torch.max(outputs,1)[1])\n",
    "        validation_loss += criterion(outputs,torch.flatten(labels.long())).item()\n",
    "        \n",
    "        accuracy += cal_acc(outputs,labels)\n",
    "\n",
    "    val_loss=validation_loss/len(validation_loader)\n",
    "    val_acc=accuracy/len(validation_loader)\n",
    "    return val_loss,val_acc,output_list,labels_list\n",
    "\n",
    "def plot_loss(model):\n",
    "    plt.plot(model.history['train_loss'], label='Loss (training data)')\n",
    "    plt.plot(model.history['validation_loss'], label='Loss (validation data)')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()\n",
    "    \n",
    "    return None\n",
    "\n",
    "def plot_accuracy(model):\n",
    "    plt.plot(model.history['train_accuracy'], label='Accuracy (training data)')\n",
    "    plt.plot(model.history['validation_accuracy'], label='Accuracy (validation data)')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(y_test, y_pred):\n",
    "    result={}\n",
    "      # Calculate AUC\n",
    "    result['AUC']=roc_auc_score(y_test,y_pred)\n",
    "    #   print(\"AUC is: \", roc_auc_score(y_test,y_pred) )\n",
    "      # recall and precision\n",
    "    result['report']=classification_report(y_test, y_pred)\n",
    "    #   print(classification_report(y_test, y_pred))\n",
    "      # confusion matrix\n",
    "    result['ConMatrix']=confusion_matrix(y_test, y_pred)\n",
    "    #   print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "      # calculate points for ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "      # Plot ROC curve\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc_score(y_test, y_pred))\n",
    "    ax.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.0])\n",
    "    ax.set_xlabel('False Positive Rate or (1 - Specifity)')\n",
    "    ax.set_ylabel('True Positive Rate or (Sensitivity)')\n",
    "    ax.set_title('Receiver Operating Characteristic')\n",
    "\n",
    "\n",
    "    return result,fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e647ebe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
